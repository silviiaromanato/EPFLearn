[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/YM0Aj0xh)
# **EPFLearn: AI Student Mentor** ðŸ“š

Introducing **EPFLearn**, a chatbot designed to answer studentsâ€™ questions on specialized course material. The chatbot leverages Googleâ€™s pre-trained [T5](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) Transformer as its foundation model, which was further fine-tuned using the StackOverflow and NLP4Education datasets.
## **Modern NLP: Course project Milestone 3**

**Team**: Antoine Bonnet, Silvia Romanato and Alexander Sternfeld (`syntax-sorcerers`)
### How to run the code

To run the code, you first need to install the requirements in the requirements.txt file.

`` pip install -r requirements.txt ``

To use our trained chatbot, you will need to download the checkpoint from [here](https://drive.google.com/drive/folders/1-8UEI-sMrCNwjiC6MENCPZZBwQhkGMdh?usp=share_link) and place it in the `checkpoints/finalChatbot` folder.

### Repository structure

Here is a list of relevant scripts used in this project. 

* [final_report_syntax_sorcerers.pdf](./final_report_syntax_sorcerers.pdf) : Final report of the project.
* [gen_model](./gen_model): Generative model
   * [chatbot.py](./gen_model/chatbot.py) : Chatbot class for interaction
   * [gen_script_syntax_sorcerers.py](./gen_model/gen_script_syntax_sorcerers.py) : Generating answers with fine-tuned chatbot
   * [finetune.py](./gen_model/finetune.py) : Fine-tuning a generative language model on specialized content
   * [load_data.py](./gen_model/load_data.py) : Data pre-processing
   * [milestone3.ipynb](./gen_model/milestone3.ipynb) : Overview
 * [reward_model](./reward_model): Reward model
   * [model.py](./reward_model/model.py) : Model class
   * [evaluate.py](./reward_model/evaluate.py) : Evaluation script
   * [milestone2.ipynb](./reward_model/milestone2.ipynb) : Overview
   * [m2_data_preparation.ipynb](./reward_model/m2_data_preparation.ipynb) : Data pre-processing for reward model
 * [checkpoints](./checkpoints) : Model checkpoints
    * [finalChatbot](./checkpoints/finalChatbot) : Final chatbot (fine-tuned on StackOverflow and EPFL datasets) 
    * [midChatbot](./checkpoints/midChatbot) : Intermediary chatbot (fine-tuned on StackOverflow dataset)
    * [rewardModel](./checkpoints/rewardModel) : Reward model (trained on StackOverflow and EPFL datasets)
 * [data](./data) : Data files. 
   * [gen_model](./data/gen_model) : Fine-tuning data for the generative model
     * [answers_syntax-sorcerers.json](./data/gen_model/answers_syntax-sorcerers.json) : Sample answers generated by chatbot
     * [gen_dataset_syntax-sorcerers_EPFL.json](./data/gen_model/gen_dataset_syntax-sorcerers_EPFL.json) : EPFL dataset
     * [gen_dataset_syntax-sorcerers_StackOverflow.json](./data/gen_model/gen_dataset_syntax-sorcerers_StackOverflow.json) : StackOverflow dataset
     * [gen_dataset_syntax-sorcerers.json](./data/gen_model/gen_dataset_syntax-sorcerers.json) : Combined EPFL and StackOverflow datasets
   * [reward_model](./data/reward_model) : Training data for the reward model
     * [reward_dataset_syntax-sorcerers_EPFL.json](./data/reward_model/reward_dataset_syntax-sorcerers_EPFL.json) : EPFL dataset
     * [reward_dataset_syntax-sorcerers_StackOverflow.json](./data/reward_model/reward_dataset_syntax-sorcerers_StackOverflow.json) : StackOverflow dataset
     * [reward_dataset_syntax-sorcerers.json](./data/reward_model/reward_dataset_syntax-sorcerers.json) : Combined EPFL and StackOverflow datasets
 * [requirements.txt](./requirements.txt) : Packages required to run the code
 * [python.txt](./python.txt) : Python version used
